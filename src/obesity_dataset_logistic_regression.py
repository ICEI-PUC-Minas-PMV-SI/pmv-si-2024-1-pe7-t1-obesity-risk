# Análise de Risco de Obesidade Usando Regressão Logística

Este projeto utiliza a Regressão Logística para prever o nível de obesidade de um indivíduo com base em diversos fatores como hábitos alimentares, tabagismo e condição física. A análise é conduzida utilizando Python e várias bibliotecas de aprendizado de máquina.

## Introdução

A obesidade é um problema de saúde pública global que afeta milhões de pessoas em todo o mundo. Este projeto visa desenvolver um modelo preditivo que possa ajudar a identificar os níveis de obesidade com alta precisão.

## Dataset

O conjunto de dados utilizado contém estimativas dos níveis de obesidade em pessoas dos países do México, Peru e Colômbia. As variáveis incluem idade, altura, peso, histórico familiar de sobrepeso, hábitos alimentares, entre outros.

## Objetivos

1. Classificar os níveis de obesidade.
2. Identificar fatores de risco.
3. Prever mudanças nos níveis de obesidade.
4. Segmentar dados para intervenções personalizadas.

## Dependências

- pandas
- scikit-learn
- imblearn

## Código

```python
# -*- coding: utf-8 -*-
"""obesity_dataset_logistic_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DvUuQdycGZDV1hZsnloYZBSwIfX5vHbm
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE

# Carregar os dados
data = pd.read_csv('ObesityDataSet.csv')

# Tratar valores ausentes
imputer = SimpleImputer(strategy='most_frequent')
data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Codificar variáveis categóricas
label_encoder = LabelEncoder()
data['Gender'] = label_encoder.fit_transform(data['Gender'])
data['family_history_with_overweight'] = label_encoder.fit_transform(data['family_history_with_overweight'])
data['FAVC'] = label_encoder.fit_transform(data['FAVC'])
data['CAEC'] = label_encoder.fit_transform(data['CAEC'])
data['SMOKE'] = label_encoder.fit_transform(data['SMOKE'])
data['SCC'] = label_encoder.fit_transform(data['SCC'])
data['CALC'] = label_encoder.fit_transform(data['CALC'])
data['MTRANS'] = label_encoder.fit_transform(data['MTRANS'])

# One-hot encoding para variáveis categóricas com mais de duas categorias
data = pd.get_dummies(data, columns=['MTRANS'])

# Codificar a variável alvo (NObeyesdad)
label_encoder = LabelEncoder()
data['NObeyesdad'] = label_encoder.fit_transform(data['NObeyesdad'])

# Dividir os dados em variáveis independentes (X) e dependente (y)
X = data.drop('NObeyesdad', axis=1)
y = data['NObeyesdad']

# Padronizar os dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Primeira divisão: 70% treinamento, 30% restante
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Segunda divisão: 50% do restante para validação, 50% para teste
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Balanceamento de classes usando SMOTE
smote = SMOTE()
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Inicializar o modelo de regressão logística
model = LogisticRegression()

# Treinar o modelo nos dados de treinamento
model.fit(X_train_resampled, y_train_resampled)

# Fazer previsões nos dados de VALIDAÇÃO
y_pred_val = model.predict(X_val)

# Avaliar o modelo nos dados de VALIDAÇÃO
accuracy_val = accuracy_score(y_val, y_pred_val)
print("Validação - Accuracy:", accuracy_val)
print("\nValidação - Classification Report:")
print(classification_report(y_val, y_pred_val))

# Fazer previsões nos dados de TESTE
y_pred = model.predict(X_test)

# Avaliar o modelo nos dados de TESTE
accuracy = accuracy_score(y_test, y_pred)
print("Teste - Accuracy:", accuracy)
print("\nTeste - Classification Report:")
print(classification_report(y_test, y_pred))
```

## Etapas de Pré-processamento

1. **Tratar valores ausentes**: Utilizamos `SimpleImputer` para substituir valores ausentes pela moda das colunas.
2. **Codificar variáveis categóricas**: Usamos `LabelEncoder` e `OneHotEncoder` para transformar variáveis categóricas em numéricas.
3. **Padronizar os dados**: Aplicamos `StandardScaler` para normalizar os dados.
4. **Divisão dos dados**: Separamos os dados em conjuntos de treino, validação e teste.
5. **Balanceamento de classes**: Utilizamos `SMOTE` para lidar com o desequilíbrio das classes.

## Treinamento do Modelo

O modelo de regressão logística foi treinado nos dados de treinamento balanceados. Em seguida, foi avaliado usando os conjuntos de dados de validação e teste, apresentando os seguintes resultados:

- **Validação - Accuracy**: Indica a precisão do modelo nos dados de validação.
- **Teste - Accuracy**: Indica a precisão do modelo nos dados de teste.
- **Classification Report**: Apresenta métricas detalhadas de desempenho, incluindo precisão, recall e F1-score.

## Resultados e Discussão

Os resultados da avaliação do modelo são apresentados em termos de acurácia, precisão, recall e F1-score. Estes indicadores ajudam a entender o desempenho do modelo em diferentes classes de obesidade.

## Conclusão

Este projeto demonstrou a aplicação da Regressão Logística para prever os níveis de obesidade com base em múltiplos fatores. As técnicas de pré-processamento e balanceamento de classes contribuíram para a melhoria da performance do modelo, tornando-o uma ferramenta útil para intervenções em saúde pública.

## Referências

- ORGANIZAÇÃO MUNDIAL DA SAÚDE (OMS). Obesidade e sobrepeso. [OMS, 2023](https://www.who.int/news-room/fact-sheets/detail/obesity-and-overweight).
- MINISTÉRIO DA SAÚDE. Vigitel 2022: Vigilância de Fatores de Risco e Proteção para Doenças Crônicas por Inquérito Telefônico. Brasília: Ministério da Saúde, 2023.
- PALECHOR, F. M.; DE LA HOZ MANOTAS, A. Obesity or CVD risk (Classify/Regressor/Cluster) [Conjunto de dados]. Kaggle, 2023. Disponível em: https://doi.org/10.34740/KAGGLE/DSV/7009925.


